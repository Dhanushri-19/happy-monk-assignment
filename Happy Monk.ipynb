{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d915201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense,Activation,Dropout \n",
    "from random import random\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "iris=pd.read_csv(\"Iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e2e1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
      "0         0.222222      0.625000       0.067797      0.041667\n",
      "1         0.166667      0.416667       0.067797      0.041667\n",
      "2         0.111111      0.500000       0.050847      0.041667\n",
      "3         0.083333      0.458333       0.084746      0.041667\n",
      "4         0.194444      0.666667       0.067797      0.041667\n",
      "..             ...           ...            ...           ...\n",
      "145       0.666667      0.416667       0.711864      0.916667\n",
      "146       0.555556      0.208333       0.677966      0.750000\n",
      "147       0.611111      0.416667       0.711864      0.791667\n",
      "148       0.527778      0.583333       0.745763      0.916667\n",
      "149       0.444444      0.416667       0.694915      0.708333\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def normalize(dataset):\n",
    "    for column in dataset.columns:\n",
    "        dataset[column]=(dataset[column]-min(dataset[column]))/(max(dataset[column])-min(dataset[column]))\n",
    "    return dataset\n",
    "data=normalize(iris.loc[:,iris.columns[:-1]])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99671b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "iris['species']= label_encoder.fit_transform(iris['Species'])\n",
    "data=pd.concat([data,iris[\"species\"]],axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1374c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(data):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(data.loc[:,data.columns[:-1]], data.loc[:,data.columns[-1]],test_size=0.33, random_state=42)\n",
    "    return  x_train,x_test,y_train,y_test\n",
    "x_train,x_test,y_train,y_test=train_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a801a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0,\n",
       "       2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2,\n",
       "       2, 1, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2,\n",
       "       1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2,\n",
       "       1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96d23737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initaial_network(n_inputs,n_outputs,neuron,x):\n",
    "    network=list()\n",
    "    hidden_layer={\"weights\":[[random() for j in range(neuron)]]*len(x),\"bias\":[[1 for j in range(neuron)]]*len(x)}\n",
    "    output_layer={\"weights\":[[random() for j in range(n_outputs)]]*len(x),\"bias\":[[1 for j in range(n_outputs)]]*len(x)}\n",
    "    network.append(hidden_layer)\n",
    "    network.append(output_layer)\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4ccd68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(k,k1,net):\n",
    "    return k+k1*net\n",
    "def softmax(a):\n",
    "    e=[math.exp(i) for i in a]\n",
    "    exp=[j/sum(e) for j in e]\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e199648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[[1,1],[1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27cc0ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(dw2,db2,dw1,db1,network):\n",
    "    for i in range(len(network)-1):\n",
    "        for j in range(len(network[i][\"weights\"])):\n",
    "            n=[]\n",
    "            b=[]\n",
    "            for k in range(len(network[i][\"weights\"][j])-1):\n",
    "                n.append((network[i][\"weights\"][j][k]-0.01*dw1[k])[0])\n",
    "                b.append(network[i][\"bias\"][j][k]-0.01*db1)\n",
    "            network[i][\"weights\"][j]=n\n",
    "            network[i][\"bias\"][j]=b\n",
    "    for j in range(len(network[-1][\"weights\"])):\n",
    "            n=[]\n",
    "            b=[]\n",
    "            for k in range(len(network[-1][\"weights\"][j])-1):\n",
    "                n.append((network[-1][\"weights\"][j][k]-0.01*dw2[k])[0])\n",
    "                b.append(network[-1][\"bias\"][j][k]-0.01*db2)\n",
    "            network[-1][\"weights\"][j]=n\n",
    "            network[-1][\"bias\"][j]=b\n",
    "    return network\n",
    "            \n",
    "\n",
    "def back_p(y_train,Z,A,network,output,K):\n",
    "    Z=np.array(Z)\n",
    "    dz2=(np.array(output)-np.array(y_train)).reshape(len(y_train),1)\n",
    "    dw2=np.matmul((np.array(A[-1]).T)/len(A[-1]),dz2)\n",
    "    db2=np.average(dz2)\n",
    "    w=np.array(network[-1][\"weights\"])\n",
    "    da1=np.matmul(w.T,dz2)\n",
    "    dz1=K[1]*np.array(A[1])\n",
    "    dw1=np.matmul(np.array(A[0]).T/len(A[0]),dz1)\n",
    "    db1=np.average(dz1)\n",
    "    k=[np.average(da1),np.average(Z[0])]\n",
    "    network=update(dw2,db2,dw1,db1,network)\n",
    "    return k,network\n",
    "def accuracy_met(actual, predicted):\n",
    "        correct = 0\n",
    "        for i in range(len(actual)):\n",
    "                if actual[i] == predicted[i]:\n",
    "                        correct += 1\n",
    "        return correct / float(len(actual)) * 100.0\n",
    "    \n",
    "def train(x_train,y_train,network,epochs):\n",
    "    k,k1=random(),random()\n",
    "    K=[k,k1]\n",
    "    for j in range(epochs):\n",
    "        print(j)\n",
    "        output=[]\n",
    "        output_values=[]\n",
    "        Z=[]\n",
    "        A=[x_train]\n",
    "        A_iter=[]\n",
    "        Z_iter=[]\n",
    "        for row in range(len(x_train)):\n",
    "            inputs=x_train[row]\n",
    "            new_a=[]\n",
    "            new_z=[]\n",
    "            for layer in range(len(network)-1):\n",
    "                for neuron,bias in zip(network[layer][\"weights\"][row],network[layer][\"bias\"][row]):\n",
    "                    z=bias\n",
    "                    for value in inputs:\n",
    "                        z+=value*neuron\n",
    "                    a=activation(z,k,k1)\n",
    "                    new_z.append(z)\n",
    "                    new_a.append(a)\n",
    "                inputs=new_a\n",
    "            Z_iter.append(new_z)\n",
    "            A_iter.append(new_a)\n",
    "            a=[]\n",
    "            for neuron,bias in zip(network[-1][\"weights\"][row],network[-1][\"bias\"][row]):\n",
    "                z=bias\n",
    "                for value in inputs:\n",
    "                    z+=value*neuron\n",
    "                a.append(z)\n",
    "            a=softmax(a)\n",
    "            output_values.append(a)\n",
    "            output.append(a.index(max(a)))\n",
    "        Z.append(Z_iter)\n",
    "        A.append(A_iter)\n",
    "        A_iter=[]\n",
    "        Z_iter=[]\n",
    "        K,network=back_p(y_train,Z,A,network,output,K)\n",
    "        k=K[0]\n",
    "        k1=K[1]\n",
    "        pred=accuracy_met(y_train,output)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa36b102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network=initaial_network(4,2,5,x_train.to_numpy())\n",
    "train(x_train.to_numpy(),y_train.to_numpy(),network,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd4529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
